{"cells":[{"cell_type":"markdown","metadata":{"id":"bHY9OdDYwtfg"},"source":["# Classificazione Binaria"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"FKwSoxfdwtfh"},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","from tqdm import tqdm\n","from time import time\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.naive_bayes import GaussianNB\n","from sklearn.neighbors import KNeighborsClassifier\n","from sklearn.svm import SVC\n","from sklearn.svm import LinearSVC\n","from sklearn.tree import DecisionTreeClassifier\n","from sklearn.ensemble import RandomForestClassifier\n","from sklearn.pipeline import Pipeline\n","from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n","\n","colonne_da_ignorare = ['author', 'text', 'subreddit', 'time', 'upper_words', 'lemmatized_text', 'severe_toxicity', 'lista_emoji']\n","file_paths = ['File.csv'] #inserire il proprio file\n","dataframes = []\n","for file_path in file_paths:\n","    df = pd.read_csv(file_path, usecols=lambda col: col not in colonne_da_ignorare)\n","    dataframes.append(df)\n","\n","df = pd.concat(dataframes, ignore_index=True)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"eB-Er1R2wtfh"},"outputs":[],"source":["# Assicurati che tutti i valori siano float\n","df['toxicity'] = pd.to_numeric(df['toxicity'], errors='coerce')\n","df.set_index('id', inplace=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8xrUOW9vwtfi"},"outputs":[],"source":["# Creazione della variabile target binaria\n","toxicity_threshold = 0.5\n","df['toxicity_binary'] = (df['toxicity'] > toxicity_threshold).astype(int)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"MWG2IlM-wtfi"},"outputs":[],"source":["# Train_Test_Split\n","df = df.fillna(0)\n","colums_to_remove = ['toxicity_binary', 'toxicity']\n","X = df.drop(columns=colums_to_remove)\n","y = df['toxicity_binary']\n","\n","X_train, X_test, y_train_binary, y_test_binary = train_test_split(X, y, test_size=0.2, random_state=42)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"m-ZwrL9kwtfi"},"outputs":[],"source":["# Modelli per la classificazione binaria\n","\n","models_binary_class = {\n","    'Logistic Regression': LogisticRegression(max_iter=1000),\n","    'Gaussian Naive Bayes': GaussianNB(),\n","    'Decision Tree': DecisionTreeClassifier(max_depth=5, min_samples_split=10),\n","    'Random Forest': RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1)\n","}\n","\n","pipelines = {name: Pipeline([\n","    ('scaler', StandardScaler()),\n","    ('model', model)\n","]) for name, model in models_binary_class.items()}\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"XnwX8wUmwtfi"},"outputs":[],"source":["outfile_path = ''"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"u_sDLcDlwtfj"},"outputs":[],"source":["# Funzione per salvare la matrice di confusione e il report di classificazione\n","def save_results(name, y_test, y_pred, is_multiclass):\n","    # Matrice di confusione\n","    unique_labels = np.unique(y_test)\n","    cm = confusion_matrix(y_test, y_pred, labels=unique_labels)\n","    cm_df = pd.DataFrame(cm, index=unique_labels, columns=unique_labels)\n","    cm_filename = f'{outfile_path}confusion_matrix_{name}.csv' # personalizza path per salvare\n","    cm_df.to_csv(cm_filename)\n","\n","    # Report di classificazione\n","    cr = classification_report(y_test, y_pred, output_dict=True)\n","    cr_df = pd.DataFrame(cr).transpose()\n","    cr_filename = f'{outfile_path}classification_report_{name}.txt' # personalizza path per salvare\n","    with open(cr_filename, 'w') as f:\n","        f.write(classification_report(y_test, y_pred))\n","\n"]},{"cell_type":"markdown","metadata":{"id":"ijY_QAKYwtfk"},"source":["### Risultati"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qF2G-rnlwtfk"},"outputs":[],"source":["# Dizionario per salvare le predizioni\n","predictions_bin = {}\n","predictions_bin['real'] = y_test_binary\n","\n","# Addestramento e valutazione dei modelli per la classificazione binaria\n","print(\"Classificazione Binaria:\")\n","for name, pipeline in tqdm(pipelines.items(), desc=\"Modelli in esecuzione\", unit=\"modello\"):\n","    start_time = time()\n","    pipeline.fit(X_train, y_train_binary)\n","    y_pred = pipeline.predict(X_test)\n","\n","    # Calcola il tempo di esecuzione per ogni modello\n","    elapsed_time = time() - start_time\n","    print(f\"{name} completed in {elapsed_time:.2f} seconds\")\n","\n","\n","    # Salvare le predizioni\n","    predictions_bin[name] = y_pred\n","\n","    # Salva confusion matrix e classification report\n","    save_results(name, y_test_binary, y_pred, is_multiclass=False)\n","\n","    # Stampa delle metriche di valutazione\n","    print(f\"Model: {name}\")\n","    print(\"Accuracy:\", accuracy_score(y_test_binary, y_pred))\n","    print(\"Confusion Matrix:\\n\", confusion_matrix(y_test_binary, y_pred))\n","    print(\"Classification Report:\\n\", classification_report(y_test_binary, y_pred))\n","    print(\"-\" * 30)\n","\n","df_predictions = pd.DataFrame(predictions_bin)\n","\n","# Salva il DataFrame in un file CSV\n","df_predictions.to_csv(outfile_path + 'binary_classification_results.csv', index=True)\n"]},{"cell_type":"markdown","metadata":{"id":"YpANIctPwtfk"},"source":["# Regressione lineare"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ucCdX55swtfk"},"outputs":[],"source":["from sklearn.linear_model import LinearRegression, Lasso, Ridge\n","from sklearn.tree import DecisionTreeRegressor\n","from sklearn.ensemble import RandomForestRegressor\n","from sklearn.metrics import mean_squared_error, r2_score\n","from sklearn.metrics import mean_absolute_error, r2_score\n","from sklearn.metrics import mean_absolute_percentage_error\n","from time import time\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9Wd2eq_Mwtfk"},"outputs":[],"source":["# Suddivisione dei dati in set di addestramento e test\n","X_train, X_test, y_train_reg, y_test_reg = train_test_split(X, df['toxicity'], test_size=0.2, random_state=42)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Ys-hlhzZwtfl"},"outputs":[],"source":["# Definizione dei modelli di regressione\n","models_regression = {\n","    'Linear Regression': LinearRegression(),\n","    'Lasso': Lasso(alpha=0.1),\n","    'Ridge': Ridge(alpha=1.0),\n","    'Decision Tree Regressor': DecisionTreeRegressor(),\n","}\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9g3GnVS9wtfl"},"outputs":[],"source":["# Funzione per salvare le metriche di regressione\n","def save_regression_results(name, y_test, y_pred):\n","    # Calcolo delle metriche\n","    mse = mean_squared_error(y_test, y_pred)\n","    mae = mean_absolute_error(y_test, y_pred)\n","    rmse = np.sqrt(mse)\n","    mape = mean_absolute_percentage_error(y_test, y_pred)\n","    r2 = r2_score(y_test, y_pred)\n","\n","    # Calcolo dell'Adjusted R-squared\n","    n = len(y_test)\n","    p = X_train.shape[1]\n","    r2_adj = 1 - (1 - r2) * (n - 1) / (n - p - 1)\n","\n","    # Salvataggio delle metriche\n","    metrics_filename = f'regression_metrics_{name}.txt'\n","    with open(metrics_filename, 'w') as f:\n","        f.write(f'Mean Squared Error (MSE): {mse}\\n')\n","        f.write(f'Mean Absolute Error (MAE): {mae}\\n')\n","        f.write(f'Root Mean Squared Error (RMSE): {rmse}\\n')\n","        f.write(f'Mean Absolute Percentage Error (MAPE): {mape}\\n')\n","        f.write(f'R-squared (R²): {r2}\\n')\n","        f.write(f'Adjusted R-squared (Adjusted R²): {r2_adj}\\n')\n","\n","    # Stampa dei risultati a video\n","    print(f\"Risultati per il modello: {name}\")\n","    print(f\"  Mean Squared Error (MSE): {mse:.4f}\")\n","    print(f\"  Mean Absolute Error (MAE): {mae:.4f}\")\n","    print(f\"  Root Mean Squared Error (RMSE): {rmse:.4f}\")\n","    print(f\"  Mean Absolute Percentage Error (MAPE): {mape:.4f}\")\n","    print(f\"  R-squared (R²): {r2:.4f}\")\n","    print(f\"  Adjusted R-squared (Adjusted R²): {r2_adj:.4f}\")\n","    print(f\"\\n\\nSalvato: {metrics_filename}\\n\\n\")\n","    print(\"-\" * 40)\n","\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"OS_fJBA76s-h"},"source":["### Risultati"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"WzJd9SONwtfl"},"outputs":[],"source":["# Dizionario per salvare le predizioni\n","predictions_reg = {}\n","predictions_reg['real'] = y_test_reg\n","\n","# Addestramento e valutazione dei modelli per la regressione\n","print(\"Regressione:\")\n","for name, model in tqdm(models_regression.items(), desc=\"Modelli in esecuzione\", unit=\"modello\"):\n","    start_time = time()\n","\n","    # Addestra il modello\n","    model.fit(X_train, y_train_reg)\n","\n","    # Effettua le previsioni\n","    y_pred = model.predict(X_test)\n","\n","    # Calcola il tempo di esecuzione per ogni modello\n","    elapsed_time = time() - start_time\n","    print(f\"{name} completed in {elapsed_time:.2f} seconds\")\n","\n","    # Salvare le predizioni\n","    predictions_reg[name] = y_pred\n","\n","    # Calcola le metriche di valutazione\n","    mse = mean_squared_error(y_test_reg, y_pred)\n","    r2 = r2_score(y_test_reg, y_pred)\n","\n","    # Stampa delle metriche di valutazione\n","    print(f\"Model: {name}\")\n","    print(\"Mean Squared Error (MSE):\", mse)\n","    print(\"R^2 Score:\", r2)\n","    print(\"-\" * 30)\n","\n","# Crea un DataFrame dalle predizioni\n","df_predictions = pd.DataFrame(predictions_reg)\n","\n","# Salva il DataFrame in un file CSV\n","outfile_path = './'  # Cambia il percorso in base alle tue necessità\n","df_predictions.to_csv(outfile_path + 'regression_results.csv', index=True)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Tr_9i6-S6s-i"},"outputs":[],"source":["from time import time\n","import pandas as pd\n","import numpy as np\n","from sklearn.metrics import (\n","    mean_squared_error,\n","    mean_absolute_error,\n","    r2_score,\n","    mean_absolute_percentage_error,\n",")\n","\n","# Dizionario per salvare le predizioni\n","predictions_reg = {}\n","predictions_reg['real'] = y_test_reg\n","\n","# Addestramento e valutazione dei modelli per la regressione\n","print(\"Regressione:\")\n","for name, model in tqdm(models_regression.items(), desc=\"Modelli in esecuzione\", unit=\"modello\"):\n","    start_time = time()\n","\n","    # Addestra il modello\n","    model.fit(X_train, y_train_reg)\n","\n","    # Effettua le previsioni\n","    y_pred = model.predict(X_test)\n","\n","    # Calcola il tempo di esecuzione per ogni modello\n","    elapsed_time = time() - start_time\n","    print(f\"{name} completed in {elapsed_time:.2f} seconds\")\n","\n","    # Salvare le predizioni\n","    predictions_reg[name] = y_pred\n","\n","    # Calcola le metriche di valutazione\n","    mse = mean_squared_error(y_test_reg, y_pred)\n","    mae = mean_absolute_error(y_test_reg, y_pred)\n","    rmse = np.sqrt(mse)\n","    mape = mean_absolute_percentage_error(y_test_reg, y_pred)\n","    r2 = r2_score(y_test_reg, y_pred)\n","\n","    # Calcolo dell'Adjusted R-squared\n","    n = len(y_test_reg)\n","    p = X_train.shape[1]\n","    r2_adj = 1 - (1 - r2) * (n - 1) / (n - p - 1)\n","\n","    # Stampa delle metriche di valutazione\n","    print(f\"Risultati per il modello: {name}\")\n","    print(f\"  Mean Squared Error (MSE): {mse:.4f}\")\n","    print(f\"  Mean Absolute Error (MAE): {mae:.4f}\")\n","    print(f\"  Root Mean Squared Error (RMSE): {rmse:.4f}\")\n","    print(f\"  Mean Absolute Percentage Error (MAPE): {mape:.4f}\")\n","    print(f\"  R-squared (R²): {r2:.4f}\")\n","    print(f\"  Adjusted R-squared (Adjusted R²): {r2_adj:.4f}\")\n","    print(\"-\" * 40)\n","\n","    # Salvataggio delle metriche in un file di testo\n","    metrics_filename = f'regression_metrics_{name}.txt'\n","    with open(metrics_filename, 'w') as f:\n","        f.write(f'Model: {name}\\n')\n","        f.write(f'Mean Squared Error (MSE): {mse:.4f}\\n')\n","        f.write(f'Mean Absolute Error (MAE): {mae:.4f}\\n')\n","        f.write(f'Root Mean Squared Error (RMSE): {rmse:.4f}\\n')\n","        f.write(f'Mean Absolute Percentage Error (MAPE): {mape:.4f}\\n')\n","        f.write(f'R-squared (R²): {r2:.4f}\\n')\n","        f.write(f'Adjusted R-squared (Adjusted R²): {r2_adj:.4f}\\n')\n","\n","    print(f\"Salvato: {metrics_filename}\\n\")\n","\n","# Crea un DataFrame dalle predizioni\n","df_predictions = pd.DataFrame(predictions_reg)\n","\n","# Salva il DataFrame in un file CSV\n","outfile_path = './'  # Cambia il percorso in base alle tue necessità\n","df_predictions.to_csv(outfile_path + 'regression_results.csv', index=True)\n","\n","print(f\"Predizioni salvate in: {outfile_path + 'regression_results.csv'}\")\n"]}],"metadata":{"colab":{"provenance":[],"collapsed_sections":["bHY9OdDYwtfg","ijY_QAKYwtfk","YpANIctPwtfk","OS_fJBA76s-h"]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.0"}},"nbformat":4,"nbformat_minor":0}